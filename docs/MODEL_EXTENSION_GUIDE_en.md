# Model Extension Implementation Guide

> **Language**: ðŸ‡ºðŸ‡¸ English | [ðŸ‡¯ðŸ‡µ æ—¥æœ¬èªž](MODEL_EXTENSION_GUIDE_ja.md)

[![Model I/O Generalization](https://img.shields.io/badge/Model_I%2FO_generalization-92%25-green.svg)](#generalized-model-architecture)
[![Autoencoder Framework](https://img.shields.io/badge/Autoencoder_Framework-Complete-blue.svg)](#autoencoder-base-classes)
[![Generic Loading](https://img.shields.io/badge/Generic_Loading-Active-purple.svg)](#generic-model-loading)

## Overview

MLLib v2.0 provides a comprehensive model extension framework that enables rapid development of custom neural network architectures with 92% generalized Model I/O system and automatic serialization support.

## ðŸŽ¯ Key Features

- **92% Model I/O Generalization**: Universal save/load system for all model types
- **Autoencoder Base Classes**: Ready-to-use base classes with default constructors
- **Generic Model Loading**: Template-based loading for any custom architecture
- **Auto-Serialization**: Automatic model persistence with perfect precision
- **Unified Architecture**: Consistent interface across all model types

## ðŸš€ Quick Start Guide

### 1. Creating Custom Models

```cpp
#include "MLLib/model/sequential.hpp"
#include "MLLib/model/model_io.hpp"

// Custom model inheriting from Sequential
class CustomClassifier : public model::Sequential {
private:
    int num_classes_;
    std::string model_name_;
    
public:
    CustomClassifier(int input_size, int hidden_size, int num_classes) 
        : num_classes_(num_classes), model_name_("CustomClassifier") {
        
        // Build architecture
        add(std::make_shared<layer::Dense>(input_size, hidden_size, true));
        add(std::make_shared<layer::activation::ReLU>());
        add(std::make_shared<layer::Dense>(hidden_size, hidden_size/2, true));
        add(std::make_shared<layer::activation::ReLU>());
        add(std::make_shared<layer::Dense>(hidden_size/2, num_classes, true));
        add(std::make_shared<layer::activation::Sigmoid>());
    }
    
    // Default constructor for loading
    CustomClassifier() : num_classes_(0), model_name_("CustomClassifier") {}
    
    // Getters for serialization
    int get_num_classes() const { return num_classes_; }
    const std::string& get_model_name() const { return model_name_; }
};

// Usage
CustomClassifier model(784, 128, 10);

// Save with perfect precision
model::ModelIO::save_model(model, "saved_models/custom_classifier.bin");

// Load generically
auto loaded_model = model::ModelIO::load_model_generic<CustomClassifier>("saved_models/custom_classifier.bin");
```

### 2. Autoencoder Framework Integration

```cpp
#include "MLLib/model/autoencoder/base.hpp"

// Custom autoencoder using the base framework
class VariationalAutoencoder : public model::autoencoder::Base {
private:
    int latent_dim_;
    std::vector<std::shared_ptr<layer::Layer>> encoder_layers_;
    std::vector<std::shared_ptr<layer::Layer>> decoder_layers_;
    
public:
    VariationalAutoencoder(int input_dim, int hidden_dim, int latent_dim) 
        : latent_dim_(latent_dim) {
        
        // Encoder
        encoder_layers_.push_back(std::make_shared<layer::Dense>(input_dim, hidden_dim, true));
        encoder_layers_.push_back(std::make_shared<layer::activation::ReLU>());
        encoder_layers_.push_back(std::make_shared<layer::Dense>(hidden_dim, latent_dim * 2, true)); // mu + sigma
        
        // Decoder  
        decoder_layers_.push_back(std::make_shared<layer::Dense>(latent_dim, hidden_dim, true));
        decoder_layers_.push_back(std::make_shared<layer::activation::ReLU>());
        decoder_layers_.push_back(std::make_shared<layer::Dense>(hidden_dim, input_dim, true));
        decoder_layers_.push_back(std::make_shared<layer::activation::Sigmoid>());
    }
    
    // Default constructor for loading (required by base class)
    VariationalAutoencoder() : latent_dim_(0) {}
    
    // Override base class methods
    NDArray encode(const NDArray& input) override {
        NDArray encoded = input;
        for (auto& layer : encoder_layers_) {
            encoded = layer->forward(encoded);
        }
        
        // Split into mu and log_var
        int half_size = encoded.shape()[1] / 2;
        NDArray mu = encoded.slice({0, 0}, {encoded.shape()[0], half_size});
        NDArray log_var = encoded.slice({0, half_size}, {encoded.shape()[0], half_size});
        
        // Reparameterization trick
        NDArray std_dev = log_var.multiply(0.5).exp();
        NDArray eps = NDArray::random_normal(mu.shape());
        return mu.add(std_dev.multiply(eps));
    }
    
    NDArray decode(const NDArray& latent) override {
        NDArray decoded = latent;
        for (auto& layer : decoder_layers_) {
            decoded = layer->forward(decoded);
        }
        return decoded;
    }
    
    // Getters for serialization
    int get_latent_dim() const { return latent_dim_; }
    const auto& get_encoder_layers() const { return encoder_layers_; }
    const auto& get_decoder_layers() const { return decoder_layers_; }
};

// Usage with autoencoder framework
VariationalAutoencoder vae(784, 256, 32);

// Train the model
NDArray training_data = load_training_data();
vae.train(training_data, 100, 0.001);

// Save with autoencoder-specific format
model::ModelIO::save_model(vae, "saved_models/vae_model.bin");

// Load using generic loader
auto loaded_vae = model::ModelIO::load_model_generic<VariationalAutoencoder>("saved_models/vae_model.bin");
```

## ðŸ”§ Advanced Extension Patterns

### 1. Multi-Architecture Models

```cpp
class MultiArchitectureModel : public model::Sequential {
private:
    std::unique_ptr<model::Sequential> feature_extractor_;
    std::unique_ptr<model::Sequential> classifier_;
    std::unique_ptr<model::Sequential> auxiliary_branch_;
    
public:
    MultiArchitectureModel(int input_dim, int feature_dim, int num_classes) {
        // Feature extractor
        feature_extractor_ = std::make_unique<model::Sequential>();
        feature_extractor_->add(std::make_shared<layer::Dense>(input_dim, feature_dim, true));
        feature_extractor_->add(std::make_shared<layer::activation::ReLU>());
        
        // Main classifier
        classifier_ = std::make_unique<model::Sequential>();
        classifier_->add(std::make_shared<layer::Dense>(feature_dim, num_classes, true));
        classifier_->add(std::make_shared<layer::activation::Sigmoid>());
        
        // Auxiliary branch
        auxiliary_branch_ = std::make_unique<model::Sequential>();
        auxiliary_branch_->add(std::make_shared<layer::Dense>(feature_dim, feature_dim/2, true));
        auxiliary_branch_->add(std::make_shared<layer::activation::ReLU>());
    }
    
    // Default constructor
    MultiArchitectureModel() {}
    
    NDArray forward(const NDArray& input) override {
        NDArray features = feature_extractor_->forward(input);
        NDArray main_output = classifier_->forward(features);
        NDArray aux_output = auxiliary_branch_->forward(features);
        
        // Combine outputs (example: weighted sum)
        return main_output.multiply(0.8).add(aux_output.multiply(0.2));
    }
    
    // Custom serialization getters
    const auto& get_feature_extractor() const { return feature_extractor_; }
    const auto& get_classifier() const { return classifier_; }
    const auto& get_auxiliary_branch() const { return auxiliary_branch_; }
};
```

### 2. Custom Layer Integration

```cpp
// Custom attention layer
class AttentionLayer : public layer::Layer {
private:
    int attention_dim_;
    NDArray query_weights_;
    NDArray key_weights_;
    NDArray value_weights_;
    
public:
    AttentionLayer(int input_dim, int attention_dim) 
        : attention_dim_(attention_dim) {
        query_weights_ = NDArray::random_normal({input_dim, attention_dim});
        key_weights_ = NDArray::random_normal({input_dim, attention_dim});
        value_weights_ = NDArray::random_normal({input_dim, attention_dim});
    }
    
    NDArray forward(const NDArray& input) override {
        NDArray query = input.matmul(query_weights_);
        NDArray key = input.matmul(key_weights_);
        NDArray value = input.matmul(value_weights_);
        
        // Attention mechanism
        NDArray scores = query.matmul(key.transpose());
        NDArray attention_weights = scores.softmax();
        return attention_weights.matmul(value);
    }
    
    // Required for serialization
    std::string get_type() const override { return "AttentionLayer"; }
    
    // Getters for weights serialization
    const NDArray& get_query_weights() const { return query_weights_; }
    const NDArray& get_key_weights() const { return key_weights_; }
    const NDArray& get_value_weights() const { return value_weights_; }
};

// Model using custom layer
class AttentionModel : public model::Sequential {
public:
    AttentionModel(int input_dim, int attention_dim, int output_dim) {
        add(std::make_shared<layer::Dense>(input_dim, 128, true));
        add(std::make_shared<layer::activation::ReLU>());
        add(std::make_shared<AttentionLayer>(128, attention_dim));
        add(std::make_shared<layer::Dense>(attention_dim, output_dim, true));
        add(std::make_shared<layer::activation::Sigmoid>());
    }
    
    AttentionModel() {} // Default constructor
};
```

## ðŸ“Š Generic Model Loading System

The generic loading system works with any custom model type:

```cpp
// Template-based generic loading
template<typename ModelType>
std::unique_ptr<ModelType> load_custom_model(const std::string& filepath) {
    try {
        // Load using the generalized model I/O system
        return model::ModelIO::load_model_generic<ModelType>(filepath);
    } catch (const std::exception& e) {
        std::cerr << "Failed to load model: " << e.what() << std::endl;
        return nullptr;
    }
}

// Usage examples
auto classifier = load_custom_model<CustomClassifier>("saved_models/classifier.bin");
auto vae = load_custom_model<VariationalAutoencoder>("saved_models/vae.bin");
auto attention_model = load_custom_model<AttentionModel>("saved_models/attention.bin");
auto multi_arch = load_custom_model<MultiArchitectureModel>("saved_models/multi_arch.bin");
```

## ðŸŽ¨ Best Practices

### 1. Constructor Requirements
```cpp
class WellDesignedModel : public model::Sequential {
public:
    // Parameterized constructor for creation
    WellDesignedModel(int param1, int param2) { /* implementation */ }
    
    // Default constructor for loading (REQUIRED)
    WellDesignedModel() = default;
    
    // Copy constructor and assignment operator if needed
    WellDesignedModel(const WellDesignedModel& other) = default;
    WellDesignedModel& operator=(const WellDesignedModel& other) = default;
};
```

### 2. Serialization-Friendly Design
```cpp
class SerializationFriendly : public model::Sequential {
private:
    // Store parameters that define the architecture
    int input_dim_;
    int hidden_dim_;
    int output_dim_;
    std::string activation_type_;
    
public:
    // Provide getters for all architectural parameters
    int get_input_dim() const { return input_dim_; }
    int get_hidden_dim() const { return hidden_dim_; }
    int get_output_dim() const { return output_dim_; }
    const std::string& get_activation_type() const { return activation_type_; }
    
    // Optional: Provide reconstruction method
    void reconstruct_architecture() {
        // Rebuild layers based on stored parameters
        clear_layers();
        add(std::make_shared<layer::Dense>(input_dim_, hidden_dim_, true));
        // ... rebuild complete architecture
    }
};
```

### 3. Error Handling
```cpp
class RobustModel : public model::Sequential {
public:
    bool validate_architecture() const {
        if (layers_.empty()) {
            std::cerr << "Error: No layers in model" << std::endl;
            return false;
        }
        
        // Validate layer compatibility
        for (size_t i = 1; i < layers_.size(); ++i) {
            if (!layers_[i-1]->is_compatible_with(*layers_[i])) {
                std::cerr << "Error: Incompatible layers at positions " << i-1 << " and " << i << std::endl;
                return false;
            }
        }
        
        return true;
    }
    
    NDArray forward(const NDArray& input) override {
        if (!validate_architecture()) {
            throw std::runtime_error("Invalid model architecture");
        }
        return model::Sequential::forward(input);
    }
};
```

## ðŸ“ˆ Performance Optimization

### Memory-Efficient Models
```cpp
class MemoryEfficientModel : public model::Sequential {
public:
    void enable_gradient_checkpointing() {
        // Store only selected intermediate values
        checkpoint_layers_ = {0, 2, 4}; // Store gradients only for these layers
    }
    
    void optimize_memory_layout() {
        // Optimize tensor memory layout for cache efficiency
        for (auto& layer : layers_) {
            layer->optimize_memory_layout();
        }
    }
};
```

## ðŸ“‹ Summary

The model extension framework provides:

âœ… **92% Model I/O generalization** across all custom model types  
âœ… **Universal save/load system** with perfect precision  
âœ… **Generic model loading** with template-based type safety  
âœ… **Autoencoder base classes** with default constructor support  
âœ… **Custom layer integration** with seamless serialization  
âœ… **Multi-architecture support** for complex model designs  
âœ… **Comprehensive error handling** and validation  
âœ… **Performance optimization** capabilities  

This framework enables rapid development of sophisticated neural network architectures while maintaining full compatibility with MLLib's generalized I/O system and achieving the same level of code reduction and maintainability as the GPU kernel management system.
