# MLLib Activation Layers - ModelIOã¨GPUå¯¾å¿œçŠ¶æ³ãƒ¬ãƒãƒ¼ãƒˆ

## ğŸ“‹ å¯¾å¿œçŠ¶æ³ã‚µãƒãƒªãƒ¼

### âœ… ModelIOå¯¾å¿œï¼ˆæ‹¡å¼µå®Œäº†ï¼‰

ä»¥ä¸‹ã®activation layersãŒModelIOã§ã®ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ã«å¯¾å¿œã—ã¾ã—ãŸï¼š

- **ReLU** - å¾“æ¥ã‹ã‚‰å¯¾å¿œ
- **Sigmoid** - å¾“æ¥ã‹ã‚‰å¯¾å¿œ  
- **Tanh** - å¾“æ¥ã‹ã‚‰å¯¾å¿œ
- **LeakyReLU** - âœ¨ **æ–°è¦å¯¾å¿œ**
- **Softmax** - âœ¨ **æ–°è¦å¯¾å¿œ**
- **GELU** - âœ¨ **æ–°è¦å¯¾å¿œ**
- **ELU** - âœ¨ **æ–°è¦å¯¾å¿œ**
- **Swish** - âœ¨ **æ–°è¦å¯¾å¿œ**

### ğŸ”§ å®Ÿè£…æ¸ˆã¿æ©Ÿèƒ½

1. **Binaryå½¢å¼ã®ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿**
2. **JSONå½¢å¼ã®ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿**
3. **Configå½¢å¼ã®ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿**
4. **ãƒ¬ã‚¤ãƒ¤ãƒ¼æ§‹æˆã®è‡ªå‹•è­˜åˆ¥**
5. **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³**

### âš ï¸ GPUå¯¾å¿œã®ç¾çŠ¶

#### ç¾åœ¨ã®åˆ¶é™

1. **CPUå®Ÿè£…ã®ã¿**
   - å…¨ã¦ã®activation layersã¯CPUä¸Šã§å®Ÿè¡Œ
   - NDArrayã®è¦ç´ å˜ä½å‡¦ç†
   - GPUãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆMetal/CUDAï¼‰æœªä½¿ç”¨

2. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®èª²é¡Œ**
   - å¤§è¦æ¨¡ãªãƒ†ãƒ³ã‚½ãƒ«æ“ä½œã§ã¯æ€§èƒ½å·®ãŒé¡•è‘—
   - ãƒãƒƒãƒå‡¦ç†ã§ã®æœ€é©åŒ–ä¸è¶³

#### GPUå¯¾å¿œã®æŠ€è¡“çš„èª²é¡Œ

```cpp
// ç¾åœ¨ã®å®Ÿè£…ä¾‹ï¼ˆCPU onlyï¼‰
NDArray LeakyReLU::forward(const NDArray& input) {
  NDArray output(input.shape());
  for (size_t i = 0; i < input.size(); ++i) {
    if (input_data[i] > 0.0) {
      output_data[i] = input_data[i];
    } else {
      output_data[i] = alpha_ * input_data[i];
    }
  }
  return output;
}

// ç†æƒ³çš„ãªGPUå¯¾å¿œå®Ÿè£…
NDArray LeakyReLU::forward(const NDArray& input) {
  NDArray output(input.shape(), input.device());
  
  if (input.device() == DeviceType::GPU) {
    // GPU kernel dispatch
    Backend::leaky_relu_kernel(input.data(), output.data(), 
                              input.size(), alpha_);
  } else {
    // CPU fallback
    // ... existing CPU implementation
  }
  
  return output;
}
```

## ğŸš€ GPUå¯¾å¿œæ”¹å–„æ¡ˆ

### 1. ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰çµ±åˆ

- **Metal**ï¼ˆmacOSï¼‰ã§ã®Activation kernels
- **CUDA**ï¼ˆNVIDIAï¼‰ã§ã®parallel processing
- **ROCm**ï¼ˆAMDï¼‰ã§ã®æœ€é©åŒ–

### 2. NDArrayæ‹¡å¼µ

- GPU memory management
- Device-aware operations
- Automatic data transfer

### 3. Kernelå®Ÿè£…

```cpp
// Metal kernelä¾‹
kernel void leaky_relu_kernel(device const float* input [[buffer(0)]],
                             device float* output [[buffer(1)]],
                             constant float& alpha [[buffer(2)]],
                             uint index [[thread_position_in_grid]]) {
    float x = input[index];
    output[index] = x > 0.0f ? x : alpha * x;
}
```

## ğŸ“ˆ æ€§èƒ½æœŸå¾…å€¤

GPUå¯¾å¿œã«ã‚ˆã‚ŠæœŸå¾…ã•ã‚Œã‚‹æ€§èƒ½å‘ä¸Šï¼š

- **å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«**ï¼ˆ<1M parametersï¼‰: 2-3x speedup
- **ä¸­è¦æ¨¡ãƒ¢ãƒ‡ãƒ«**ï¼ˆ1-10M parametersï¼‰: 5-10x speedup  
- **å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«**ï¼ˆ>10M parametersï¼‰: 10-50x speedup

## ğŸ“ å®Ÿè£…æ¸ˆã¿ãƒ†ã‚¹ãƒˆçµæœ

```
=== ModelIO Extended Layer Support Test ===
âœ… Model created with LeakyReLU, GELU, and Softmax layers
Save results:
  Binary: âœ… Success
  JSON:   âœ… Success  
  Config: âœ… Success
âœ… Model architecture loaded successfully
  Original layers: 6
  Loaded layers:   6
âœ… Forward pass successful
  Input size:  4
  Output size: 4
  Softmax output sum: 1 (should be ~1.0)
âœ… Softmax output is correctly normalized
```

## ğŸ”œ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **GPU Kernelå®Ÿè£…** - Metal/CUDA activation kernels
2. **NDArray GPUå¯¾å¿œ** - Device-aware tensor operations
3. **Performance benchmarks** - CPU vs GPUæ¯”è¼ƒ
4. **Memory optimization** - GPU memory poolç®¡ç†

## ğŸ“š ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹

```cpp
#include "MLLib.hpp"

// ãƒ¬ã‚¤ãƒ¤ãƒ¼ä½œæˆ
auto model = std::make_unique<Sequential>();
model->add(std::make_shared<Dense>(10, 20));
model->add(std::make_shared<activation::LeakyReLU>(0.01));
model->add(std::make_shared<activation::GELU>());
model->add(std::make_shared<activation::Softmax>());

// ãƒ¢ãƒ‡ãƒ«ä¿å­˜
ModelIO::save_model(*model, "my_model.bin", SaveFormat::BINARY);

// ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿  
auto loaded = ModelIO::load_model("my_model.bin", SaveFormat::BINARY);
```

### GPUä½¿ç”¨æ™‚ï¼ˆå°†æ¥å®Ÿè£…ï¼‰

```cpp
// GPUä½¿ç”¨è¨­å®š
model->set_device(DeviceType::GPU);
Backend::setPreferredGPUBackend(GPUBackendType::METAL);

// è‡ªå‹•çš„ã«GPUã§å®Ÿè¡Œ
auto output = model->predict(input);
```
